{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFfDFDhs7JWn",
        "outputId": "453e5b4d-880a-4e20-af9a-0481d49d5010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if GPU is available\n",
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpu_devices:\n",
        "    print(\"GPU available\")\n",
        "else:\n",
        "    print(\"GPU not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Function to check if a row has consistent column count\n",
        "def is_consistent_row(row, num_columns):\n",
        "    return len(row) == num_columns\n",
        "\n",
        "# Read the CSV file and remove rows with inconsistent column counts\n",
        "input_file = 'cicddos2019_dataset.csv'\n",
        "output_file = 'cicddos2019_dataset_clean.csv'\n",
        "\n",
        "with open(input_file, 'r', newline='') as infile, open(output_file, 'w', newline='') as outfile:\n",
        "    reader = csv.reader(infile)\n",
        "    writer = csv.writer(outfile)\n",
        "\n",
        "    # Get the header row and determine the number of columns\n",
        "    header = next(reader)\n",
        "    num_columns = len(header)\n",
        "    writer.writerow(header)\n",
        "\n",
        "    # Iterate over rows, filter out inconsistent rows, and write the consistent rows to the output file\n",
        "    for row in reader:\n",
        "        if is_consistent_row(row, num_columns):\n",
        "            writer.writerow(row)\n"
      ],
      "metadata": {
        "id": "FupM9BAR7iIO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the cleaned dataset\n",
        "df = pd.read_csv('cicddos2019_dataset_clean.csv')\n",
        "\n",
        "# Preprocessing\n",
        "# 1. Handling Missing Values (if any)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "encoder_protocol = LabelEncoder()\n",
        "df['Protocol'] = encoder_protocol.fit_transform(df['Protocol'])\n",
        "\n",
        "encoder_label = LabelEncoder()\n",
        "df['Label'] = encoder_label.fit_transform(df['Label'])\n",
        "\n",
        "# Update the 'Class' column values\n",
        "df['Class'] = df['Class'].map({'Attack': 1, 'Benign': 0})\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_columns = ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total',\n",
        "                     'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
        "                     'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
        "                     'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std',\n",
        "                     'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
        "                     'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min',\n",
        "                     'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean',\n",
        "                     'Packet Length Std', 'Packet Length Variance', 'Avg Packet Size', 'Avg Fwd Segment Size',\n",
        "                     'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n",
        "                     'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
        "                     'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes',\n",
        "                     'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
        "                     'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Remove non-numeric columns\n",
        "df = df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Print the first 5 rows of the dataframe\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Splitting the dataset into features (X) and target (y)\n",
        "X = df.drop(columns=['Class'])  # Features\n",
        "y = df['Class']  # Target variable\n",
        "\n",
        "# Splitting the dataset into training (70%), testing (15%), and validation (15%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Printing the shapes of the resulting datasets\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLbOXfWOjY5N",
        "outputId": "b1a526c2-dd79-4ce8-a2bf-2aae72edb13b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  Protocol  Flow Duration  Total Fwd Packets  \\\n",
            "0           0         2   1.805269e-03           0.000058   \n",
            "1           1         2   8.333421e-09           0.000012   \n",
            "2           2         2   3.916708e-07           0.000012   \n",
            "3           3         2   8.943260e-04           0.000035   \n",
            "4           4         2   8.939260e-04           0.000035   \n",
            "\n",
            "   Total Backward Packets  Fwd Packets Length Total  Bwd Packets Length Total  \\\n",
            "0                     0.0                  0.000137                       0.0   \n",
            "1                     0.0                  0.000053                       0.0   \n",
            "2                     0.0                  0.000050                       0.0   \n",
            "3                     0.0                  0.000092                       0.0   \n",
            "4                     0.0                  0.000094                       0.0   \n",
            "\n",
            "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  ...  \\\n",
            "0               0.012235               0.150634                0.115412  ...   \n",
            "1               0.012484               0.188175                0.132989  ...   \n",
            "2               0.011924               0.179728                0.127019  ...   \n",
            "3               0.011488               0.154857                0.115909  ...   \n",
            "4               0.012111               0.154857                0.119226  ...   \n",
            "\n",
            "   Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \\\n",
            "0          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "1          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "2          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "3          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "4          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "\n",
            "   Idle Max  Idle Min  Label  Class  \n",
            "0       0.0       0.0     14      1  \n",
            "1       0.0       0.0     14      1  \n",
            "2       0.0       0.0     14      1  \n",
            "3       0.0       0.0     14      1  \n",
            "4       0.0       0.0     14      1  \n",
            "\n",
            "[5 rows x 80 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the cleaned dataset\n",
        "df = pd.read_csv('cicddos2019_dataset_clean.csv')\n",
        "\n",
        "# Preprocessing\n",
        "# 1. Handling Missing Values (if any)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "encoder_protocol = LabelEncoder()\n",
        "df['Protocol'] = encoder_protocol.fit_transform(df['Protocol'])\n",
        "\n",
        "encoder_label = LabelEncoder()\n",
        "df['Label'] = encoder_label.fit_transform(df['Label'])\n",
        "\n",
        "# Update the 'Class' column values\n",
        "df['Class'] = df['Class'].map({'Attack': 1, 'Benign': 0})\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_columns = ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total',\n",
        "                     'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
        "                     'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
        "                     'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std',\n",
        "                     'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
        "                     'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min',\n",
        "                     'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean',\n",
        "                     'Packet Length Std', 'Packet Length Variance', 'Avg Packet Size', 'Avg Fwd Segment Size',\n",
        "                     'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n",
        "                     'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
        "                     'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes',\n",
        "                     'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
        "                     'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Remove non-numeric columns\n",
        "df = df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Print the first 5 rows of the dataframe\n",
        "print(df.head())\n",
        "\n",
        "# Calculate time taken for preprocessing\n",
        "preprocessing_time = time.time() - start_time\n",
        "print(\"Preprocessing time:\", preprocessing_time, \"seconds\")\n",
        "\n",
        "# Splitting the dataset into features (X) and target (y)\n",
        "X = df.drop(columns=['Class'])  # Features\n",
        "y = df['Class']  # Target variable\n",
        "\n",
        "# Splitting the dataset into training (70%), testing (15%), and validation (15%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Printing the shapes of the resulting datasets\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
        "\n",
        "print(y_train.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmUptTTHqLav",
        "outputId": "1c65a472-6321-452a-eb46-e83cf3adad24"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  Protocol  Flow Duration  Total Fwd Packets  \\\n",
            "0           0         2   1.805269e-03           0.000058   \n",
            "1           1         2   8.333421e-09           0.000012   \n",
            "2           2         2   3.916708e-07           0.000012   \n",
            "3           3         2   8.943260e-04           0.000035   \n",
            "4           4         2   8.939260e-04           0.000035   \n",
            "\n",
            "   Total Backward Packets  Fwd Packets Length Total  Bwd Packets Length Total  \\\n",
            "0                     0.0                  0.000137                       0.0   \n",
            "1                     0.0                  0.000053                       0.0   \n",
            "2                     0.0                  0.000050                       0.0   \n",
            "3                     0.0                  0.000092                       0.0   \n",
            "4                     0.0                  0.000094                       0.0   \n",
            "\n",
            "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  ...  \\\n",
            "0               0.012235               0.150634                0.115412  ...   \n",
            "1               0.012484               0.188175                0.132989  ...   \n",
            "2               0.011924               0.179728                0.127019  ...   \n",
            "3               0.011488               0.154857                0.115909  ...   \n",
            "4               0.012111               0.154857                0.119226  ...   \n",
            "\n",
            "   Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \\\n",
            "0          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "1          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "2          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "3          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "4          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "\n",
            "   Idle Max  Idle Min  Label  Class  \n",
            "0       0.0       0.0     14      1  \n",
            "1       0.0       0.0     14      1  \n",
            "2       0.0       0.0     14      1  \n",
            "3       0.0       0.0     14      1  \n",
            "4       0.0       0.0     14      1  \n",
            "\n",
            "[5 rows x 80 columns]\n",
            "Preprocessing time: 8.18675422668457 seconds\n",
            "Training set shape: (301959, 79) (301959,)\n",
            "Testing set shape: (64706, 79) (64706,)\n",
            "Validation set shape: (64706, 79) (64706,)\n",
            "402427    1\n",
            "34051     1\n",
            "136914    1\n",
            "56522     1\n",
            "19040     0\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using GPU for data processing."
      ],
      "metadata": {
        "id": "rIE_f_i3siJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n",
        "\n",
        "# Calculate the time taken for training\n",
        "training_time = time.time() - start_time\n",
        "print(\"Training time:\", training_time, \"seconds\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndPc98X_sgE7",
        "outputId": "96a5c291-4787-4f10-a644-4e1fee69332f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4719/4719 [==============================] - 25s 5ms/step - loss: 17843.9570 - accuracy: 0.7827 - val_loss: 10029.9736 - val_accuracy: 0.9678\n",
            "Epoch 2/10\n",
            "4719/4719 [==============================] - 23s 5ms/step - loss: 4224.8311 - accuracy: 0.8503 - val_loss: 321.0934 - val_accuracy: 0.8589\n",
            "Epoch 3/10\n",
            "4719/4719 [==============================] - 21s 4ms/step - loss: 180.7543 - accuracy: 0.8611 - val_loss: 119.8093 - val_accuracy: 0.8521\n",
            "Epoch 4/10\n",
            "4719/4719 [==============================] - 24s 5ms/step - loss: 142.0417 - accuracy: 0.8737 - val_loss: 18.9621 - val_accuracy: 0.9680\n",
            "Epoch 5/10\n",
            "4719/4719 [==============================] - 20s 4ms/step - loss: 92.4435 - accuracy: 0.8865 - val_loss: 38.5345 - val_accuracy: 0.6848\n",
            "Epoch 6/10\n",
            "4719/4719 [==============================] - 21s 4ms/step - loss: 151.9953 - accuracy: 0.9169 - val_loss: 51.9163 - val_accuracy: 0.9679\n",
            "Epoch 7/10\n",
            "4719/4719 [==============================] - 23s 5ms/step - loss: 90.7909 - accuracy: 0.9301 - val_loss: 90.5438 - val_accuracy: 0.9678\n",
            "Epoch 8/10\n",
            "4719/4719 [==============================] - 21s 5ms/step - loss: 1382.7845 - accuracy: 0.9293 - val_loss: 14.4593 - val_accuracy: 0.9728\n",
            "Epoch 9/10\n",
            "4719/4719 [==============================] - 21s 5ms/step - loss: 82.8943 - accuracy: 0.9649 - val_loss: 85.8169 - val_accuracy: 0.9266\n",
            "Epoch 10/10\n",
            "4719/4719 [==============================] - 22s 5ms/step - loss: 75.7760 - accuracy: 0.9652 - val_loss: 102.9037 - val_accuracy: 0.9866\n",
            "Training time: 223.03060960769653 seconds\n",
            "2023/2023 [==============================] - 5s 2ms/step - loss: 1367.6740 - accuracy: 0.9873\n",
            "Test loss: 1367.6739501953125\n",
            "Test accuracy: 0.987250030040741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a accuracy of 98% and a training time of 223 seconds ðŸ™Œ"
      ],
      "metadata": {
        "id": "z8ZebDZjvnZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import time\n",
        "\n",
        "# Check if GPU is available\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print('GPU is available.')\n",
        "else:\n",
        "    print('GPU is not available. Make sure you have set up TensorFlow with GPU support.')\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n",
        "\n",
        "# Calculate the time taken for training\n",
        "training_time = time.time() - start_time\n",
        "print(\"Training time:\", training_time, \"seconds\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "touomUqyvmrb",
        "outputId": "74835a1c-d769-4f74-e7cc-f4fb5b964490"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available.\n",
            "Epoch 1/10\n",
            "4719/4719 [==============================] - 24s 5ms/step - loss: 28192.5723 - accuracy: 0.7439 - val_loss: 19393.6484 - val_accuracy: 0.5018\n",
            "Epoch 2/10\n",
            "4719/4719 [==============================] - 21s 4ms/step - loss: 8858.8857 - accuracy: 0.8131 - val_loss: 5133.3945 - val_accuracy: 0.7305\n",
            "Epoch 3/10\n",
            "4719/4719 [==============================] - 21s 4ms/step - loss: 2807.6133 - accuracy: 0.8108 - val_loss: 121.1845 - val_accuracy: 0.9745\n",
            "Epoch 4/10\n",
            "4719/4719 [==============================] - 22s 5ms/step - loss: 1009.2772 - accuracy: 0.8693 - val_loss: 424.3452 - val_accuracy: 0.9969\n",
            "Epoch 5/10\n",
            "4719/4719 [==============================] - 21s 4ms/step - loss: 171.3034 - accuracy: 0.8884 - val_loss: 9.4715 - val_accuracy: 0.9769\n",
            "Epoch 6/10\n",
            "4719/4719 [==============================] - 22s 5ms/step - loss: 586.0389 - accuracy: 0.9035 - val_loss: 87.1082 - val_accuracy: 0.9612\n",
            "Epoch 7/10\n",
            "4719/4719 [==============================] - 22s 5ms/step - loss: 220.5396 - accuracy: 0.8900 - val_loss: 2951.2473 - val_accuracy: 0.8888\n",
            "Epoch 8/10\n",
            "4719/4719 [==============================] - 21s 4ms/step - loss: 722.3275 - accuracy: 0.9120 - val_loss: 42.2705 - val_accuracy: 0.9722\n",
            "Epoch 9/10\n",
            "4719/4719 [==============================] - 25s 5ms/step - loss: 329.4197 - accuracy: 0.9556 - val_loss: 64.0564 - val_accuracy: 0.9934\n",
            "Epoch 10/10\n",
            "4719/4719 [==============================] - 22s 5ms/step - loss: 578.3995 - accuracy: 0.9498 - val_loss: 22.6494 - val_accuracy: 0.6961\n",
            "Training time: 220.63765716552734 seconds\n",
            "2023/2023 [==============================] - 7s 3ms/step - loss: 127.1195 - accuracy: 0.6957\n",
            "Test loss: 127.11951446533203\n",
            "Test accuracy: 0.6956542134284973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import time\n",
        "\n",
        "# Check GPU availability and set memory growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU is available and memory growth is set.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU available, falling back to CPU.\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n",
        "\n",
        "# Calculate the time taken for training\n",
        "training_time = time.time() - start_time\n",
        "print(\"Training time:\", training_time, \"seconds\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy88YIGayLBH",
        "outputId": "4b92d950-c7f9-44ca-fb9d-19730d44529a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "Epoch 1/10\n",
            "4719/4719 [==============================] - 22s 5ms/step - loss: 24584.6875 - accuracy: 0.7660 - val_loss: 25643.8730 - val_accuracy: 0.8915\n",
            "Epoch 2/10\n",
            "4719/4719 [==============================] - 21s 4ms/step - loss: 7965.6626 - accuracy: 0.8425 - val_loss: 6435.9897 - val_accuracy: 0.8332\n",
            "Epoch 3/10\n",
            "4719/4719 [==============================] - 23s 5ms/step - loss: 3792.6174 - accuracy: 0.8714 - val_loss: 1653.0834 - val_accuracy: 0.8753\n",
            "Epoch 4/10\n",
            "4719/4719 [==============================] - 21s 4ms/step - loss: 491.7817 - accuracy: 0.8936 - val_loss: 40.4494 - val_accuracy: 0.9781\n",
            "Epoch 5/10\n",
            "4719/4719 [==============================] - 24s 5ms/step - loss: 134.2355 - accuracy: 0.8937 - val_loss: 45.7682 - val_accuracy: 0.6377\n",
            "Epoch 6/10\n",
            "4719/4719 [==============================] - 24s 5ms/step - loss: 392.5529 - accuracy: 0.9200 - val_loss: 4.0601 - val_accuracy: 0.9128\n",
            "Epoch 7/10\n",
            "4719/4719 [==============================] - 29s 6ms/step - loss: 2.8335 - accuracy: 0.9468 - val_loss: 10.2360 - val_accuracy: 0.8991\n",
            "Epoch 8/10\n",
            "4719/4719 [==============================] - 30s 6ms/step - loss: 716.8181 - accuracy: 0.9294 - val_loss: 64.7124 - val_accuracy: 0.8667\n",
            "Epoch 9/10\n",
            "4719/4719 [==============================] - 21s 4ms/step - loss: 33.0977 - accuracy: 0.9465 - val_loss: 0.1143 - val_accuracy: 0.9861\n",
            "Epoch 10/10\n",
            "4719/4719 [==============================] - 21s 5ms/step - loss: 0.9860 - accuracy: 0.9610 - val_loss: 15.1022 - val_accuracy: 0.9949\n",
            "Training time: 263.7041485309601 seconds\n",
            "2023/2023 [==============================] - 7s 3ms/step - loss: 199.0913 - accuracy: 0.9947\n",
            "Test loss: 199.09127807617188\n",
            "Test accuracy: 0.9947454929351807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code has minor changes to reduce training time."
      ],
      "metadata": {
        "id": "cVrTEvClysfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import time\n",
        "\n",
        "# Check GPU availability and set memory growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU is available and memory growth is set.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU available, falling back to CPU.\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=128)\n",
        "\n",
        "# Calculate the time taken for training\n",
        "training_time = time.time() - start_time\n",
        "print(\"Training time:\", training_time, \"seconds\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asqlXkZOymgr",
        "outputId": "57789da3-0437-40cb-d5bd-9044ee477d7b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "Epoch 1/20\n",
            "2360/2360 [==============================] - 14s 5ms/step - loss: 8011.8345 - accuracy: 0.7052 - val_loss: 909.5580 - val_accuracy: 0.3702\n",
            "Epoch 2/20\n",
            "2360/2360 [==============================] - 13s 5ms/step - loss: 774.1266 - accuracy: 0.7250 - val_loss: 552.2647 - val_accuracy: 0.8980\n",
            "Epoch 3/20\n",
            "2360/2360 [==============================] - 12s 5ms/step - loss: 259.5239 - accuracy: 0.7753 - val_loss: 295.8536 - val_accuracy: 0.7889\n",
            "Epoch 4/20\n",
            "2360/2360 [==============================] - 10s 4ms/step - loss: 84.8428 - accuracy: 0.8170 - val_loss: 152.3625 - val_accuracy: 0.3573\n",
            "Epoch 5/20\n",
            "2360/2360 [==============================] - 13s 5ms/step - loss: 806.7695 - accuracy: 0.6426 - val_loss: 175.0585 - val_accuracy: 0.7735\n",
            "Epoch 6/20\n",
            "2360/2360 [==============================] - 12s 5ms/step - loss: 164.9169 - accuracy: 0.7736 - val_loss: 190.3438 - val_accuracy: 0.7734\n",
            "Epoch 7/20\n",
            "2360/2360 [==============================] - 12s 5ms/step - loss: 144.9144 - accuracy: 0.7736 - val_loss: 0.5351 - val_accuracy: 0.7733\n",
            "Epoch 8/20\n",
            "2360/2360 [==============================] - 11s 5ms/step - loss: 1.2274 - accuracy: 0.7734 - val_loss: 0.5350 - val_accuracy: 0.7734\n",
            "Epoch 9/20\n",
            "2360/2360 [==============================] - 13s 5ms/step - loss: 0.5344 - accuracy: 0.7737 - val_loss: 0.5348 - val_accuracy: 0.7734\n",
            "Epoch 10/20\n",
            "2360/2360 [==============================] - 13s 5ms/step - loss: 0.5343 - accuracy: 0.7737 - val_loss: 0.5348 - val_accuracy: 0.7734\n",
            "Epoch 11/20\n",
            "2360/2360 [==============================] - 12s 5ms/step - loss: 0.5341 - accuracy: 0.7737 - val_loss: 0.5345 - val_accuracy: 0.7734\n",
            "Epoch 12/20\n",
            "2360/2360 [==============================] - 11s 4ms/step - loss: 0.5432 - accuracy: 0.7736 - val_loss: 0.5349 - val_accuracy: 0.7733\n",
            "Epoch 13/20\n",
            "2360/2360 [==============================] - 12s 5ms/step - loss: 2.0075 - accuracy: 0.7736 - val_loss: 0.5344 - val_accuracy: 0.7733\n",
            "Epoch 14/20\n",
            "2360/2360 [==============================] - 12s 5ms/step - loss: 0.6026 - accuracy: 0.7736 - val_loss: 0.5344 - val_accuracy: 0.7731\n",
            "Epoch 15/20\n",
            "2360/2360 [==============================] - 12s 5ms/step - loss: 0.5461 - accuracy: 0.7732 - val_loss: 0.5356 - val_accuracy: 0.7727\n",
            "Epoch 16/20\n",
            "2360/2360 [==============================] - 11s 5ms/step - loss: 0.5370 - accuracy: 0.7731 - val_loss: 0.5355 - val_accuracy: 0.7727\n",
            "Epoch 17/20\n",
            "2360/2360 [==============================] - 12s 5ms/step - loss: 0.5350 - accuracy: 0.7731 - val_loss: 0.5354 - val_accuracy: 0.7727\n",
            "Epoch 18/20\n",
            "2360/2360 [==============================] - 12s 5ms/step - loss: 0.5553 - accuracy: 0.7731 - val_loss: 0.5355 - val_accuracy: 0.7727\n",
            "Epoch 19/20\n",
            "2360/2360 [==============================] - 13s 6ms/step - loss: 0.5349 - accuracy: 0.7731 - val_loss: 5.5667 - val_accuracy: 0.7727\n",
            "Epoch 20/20\n",
            "2360/2360 [==============================] - 11s 4ms/step - loss: 7.6705 - accuracy: 0.7731 - val_loss: 0.5354 - val_accuracy: 0.7727\n",
            "Training time: 241.6011097431183 seconds\n",
            "2023/2023 [==============================] - 6s 3ms/step - loss: 0.5330 - accuracy: 0.7747\n",
            "Test loss: 0.5329746007919312\n",
            "Test accuracy: 0.7746886014938354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code has major changes by making the model complex to reduce training time."
      ],
      "metadata": {
        "id": "gxWLJt4Wy0kD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import time\n",
        "\n",
        "# Check GPU availability and set memory growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU is available and memory growth is set.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU available, falling back to CPU.\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with larger batch size\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=1024)\n",
        "\n",
        "# Calculate the time taken for training\n",
        "training_time = time.time() - start_time\n",
        "print(\"Training time:\", training_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unyOwBuH0XgG",
        "outputId": "ce2d9120-851f-44cd-d397-a2fa95aefedf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "Epoch 1/10\n",
            "295/295 [==============================] - 5s 9ms/step - loss: 73752.8281 - accuracy: 0.6630 - val_loss: 17095.6406 - val_accuracy: 0.7364\n",
            "Epoch 2/10\n",
            "295/295 [==============================] - 2s 7ms/step - loss: 27104.0527 - accuracy: 0.6752 - val_loss: 14059.4561 - val_accuracy: 0.7739\n",
            "Epoch 3/10\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 13009.1914 - accuracy: 0.6813 - val_loss: 3979.4050 - val_accuracy: 0.7731\n",
            "Epoch 4/10\n",
            "295/295 [==============================] - 2s 5ms/step - loss: 5071.0645 - accuracy: 0.6910 - val_loss: 7199.1748 - val_accuracy: 0.7896\n",
            "Epoch 5/10\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 2313.4548 - accuracy: 0.7032 - val_loss: 454.3734 - val_accuracy: 0.2792\n",
            "Epoch 6/10\n",
            "295/295 [==============================] - 2s 5ms/step - loss: 148.0992 - accuracy: 0.6932 - val_loss: 292.9650 - val_accuracy: 0.7766\n",
            "Epoch 7/10\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 63.9957 - accuracy: 0.7192 - val_loss: 206.6471 - val_accuracy: 0.3456\n",
            "Epoch 8/10\n",
            "295/295 [==============================] - 2s 5ms/step - loss: 111.7806 - accuracy: 0.7068 - val_loss: 18089.7305 - val_accuracy: 0.3722\n",
            "Epoch 9/10\n",
            "295/295 [==============================] - 2s 7ms/step - loss: 29848.7012 - accuracy: 0.6743 - val_loss: 9053.0488 - val_accuracy: 0.7701\n",
            "Epoch 10/10\n",
            "295/295 [==============================] - 2s 8ms/step - loss: 1801.8152 - accuracy: 0.6924 - val_loss: 513.3236 - val_accuracy: 0.7889\n",
            "Training time: 21.909894466400146 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import time\n",
        "\n",
        "# Check GPU availability and set memory growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU is available and memory growth is set.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU available, falling back to CPU.\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with larger batch size\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=1024)\n",
        "\n",
        "# Calculate the time taken for training\n",
        "training_time = time.time() - start_time\n",
        "print(\"Training time:\", training_time, \"seconds\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5dtPZAY08yB",
        "outputId": "3e0b8414-220d-4b34-f07c-c55da18fb9d2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "Epoch 1/20\n",
            "295/295 [==============================] - 3s 7ms/step - loss: 69779.5859 - accuracy: 0.6658 - val_loss: 4321.1343 - val_accuracy: 0.7922\n",
            "Epoch 2/20\n",
            "295/295 [==============================] - 2s 7ms/step - loss: 33896.5273 - accuracy: 0.6777 - val_loss: 2678.2034 - val_accuracy: 0.7732\n",
            "Epoch 3/20\n",
            "295/295 [==============================] - 2s 8ms/step - loss: 14752.1533 - accuracy: 0.6741 - val_loss: 15516.2656 - val_accuracy: 0.7734\n",
            "Epoch 4/20\n",
            "295/295 [==============================] - 2s 6ms/step - loss: 12313.9326 - accuracy: 0.6929 - val_loss: 1470.7772 - val_accuracy: 0.7799\n",
            "Epoch 5/20\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 2351.1096 - accuracy: 0.6996 - val_loss: 3138.9333 - val_accuracy: 0.7769\n",
            "Epoch 6/20\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 1502.6542 - accuracy: 0.7062 - val_loss: 809.3448 - val_accuracy: 0.7734\n",
            "Epoch 7/20\n",
            "295/295 [==============================] - 2s 5ms/step - loss: 1604.7765 - accuracy: 0.7049 - val_loss: 3265.7310 - val_accuracy: 0.7948\n",
            "Epoch 8/20\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 4711.5938 - accuracy: 0.7018 - val_loss: 1444.9348 - val_accuracy: 0.7769\n",
            "Epoch 9/20\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 845.8039 - accuracy: 0.7086 - val_loss: 182.6456 - val_accuracy: 0.8397\n",
            "Epoch 10/20\n",
            "295/295 [==============================] - 2s 6ms/step - loss: 106.9646 - accuracy: 0.6934 - val_loss: 340.7446 - val_accuracy: 0.8442\n",
            "Epoch 11/20\n",
            "295/295 [==============================] - 2s 8ms/step - loss: 112.4277 - accuracy: 0.7135 - val_loss: 78.2089 - val_accuracy: 0.7755\n",
            "Epoch 12/20\n",
            "295/295 [==============================] - 2s 8ms/step - loss: 2359.6753 - accuracy: 0.7244 - val_loss: 38166.1602 - val_accuracy: 0.7732\n",
            "Epoch 13/20\n",
            "295/295 [==============================] - 2s 6ms/step - loss: 13379.6875 - accuracy: 0.6820 - val_loss: 1996.0182 - val_accuracy: 0.7732\n",
            "Epoch 14/20\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 2192.3271 - accuracy: 0.6931 - val_loss: 1294.7800 - val_accuracy: 0.7769\n",
            "Epoch 15/20\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 1043.5781 - accuracy: 0.7110 - val_loss: 1528.8959 - val_accuracy: 0.6062\n",
            "Epoch 16/20\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 513.5156 - accuracy: 0.7277 - val_loss: 287.7399 - val_accuracy: 0.7775\n",
            "Epoch 17/20\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 156.5918 - accuracy: 0.7398 - val_loss: 142.8464 - val_accuracy: 0.7966\n",
            "Epoch 18/20\n",
            "295/295 [==============================] - 1s 5ms/step - loss: 213.7948 - accuracy: 0.7540 - val_loss: 179.7827 - val_accuracy: 0.8209\n",
            "Epoch 19/20\n",
            "295/295 [==============================] - 2s 5ms/step - loss: 34.3783 - accuracy: 0.7799 - val_loss: 20.5803 - val_accuracy: 0.5390\n",
            "Epoch 20/20\n",
            "295/295 [==============================] - 2s 8ms/step - loss: 31.2718 - accuracy: 0.7614 - val_loss: 65.2260 - val_accuracy: 0.7663\n",
            "Training time: 42.38820695877075 seconds\n",
            "2023/2023 [==============================] - 5s 2ms/step - loss: 762.0725 - accuracy: 0.7675\n",
            "Test Accuracy: 0.7674868106842041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The X_train_preprocessed is taking a lot of time to upload to the colab."
      ],
      "metadata": {
        "id": "J4_OXKpMxwL5"
      }
    }
  ]
}