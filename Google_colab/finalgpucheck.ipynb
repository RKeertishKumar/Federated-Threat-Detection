{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkbhJSWY6QO0",
        "outputId": "a92ac843-c653-4ef5-e759-b1af3e63821d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if GPU is available\n",
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpu_devices:\n",
        "    print(\"GPU available\")\n",
        "else:\n",
        "    print(\"GPU not available\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Function to check if a row has consistent column count\n",
        "def is_consistent_row(row, num_columns):\n",
        "    return len(row) == num_columns\n",
        "\n",
        "# Read the CSV file and remove rows with inconsistent column counts\n",
        "input_file = 'cicddos2019_dataset.csv'\n",
        "output_file = 'cicddos2019_dataset_clean.csv'\n",
        "\n",
        "with open(input_file, 'r', newline='') as infile, open(output_file, 'w', newline='') as outfile:\n",
        "    reader = csv.reader(infile)\n",
        "    writer = csv.writer(outfile)\n",
        "\n",
        "    # Get the header row and determine the number of columns\n",
        "    header = next(reader)\n",
        "    num_columns = len(header)\n",
        "    writer.writerow(header)\n",
        "\n",
        "    # Iterate over rows, filter out inconsistent rows, and write the consistent rows to the output file\n",
        "    for row in reader:\n",
        "        if is_consistent_row(row, num_columns):\n",
        "            writer.writerow(row)\n"
      ],
      "metadata": {
        "id": "ep42e2ahAP_I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre processing code."
      ],
      "metadata": {
        "id": "DTJ1bijM7LG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the cleaned dataset\n",
        "df = pd.read_csv('cicddos2019_dataset_clean.csv')\n",
        "\n",
        "# Preprocessing\n",
        "# 1. Handling Missing Values (if any)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "encoder_protocol = LabelEncoder()\n",
        "df['Protocol'] = encoder_protocol.fit_transform(df['Protocol'])\n",
        "\n",
        "encoder_label = LabelEncoder()\n",
        "df['Label'] = encoder_label.fit_transform(df['Label'])\n",
        "\n",
        "# Update the 'Class' column values\n",
        "df['Class'] = df['Class'].map({'Attack': 1, 'Benign': 0})\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_columns = ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total',\n",
        "                     'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
        "                     'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
        "                     'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std',\n",
        "                     'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
        "                     'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min',\n",
        "                     'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean',\n",
        "                     'Packet Length Std', 'Packet Length Variance', 'Avg Packet Size', 'Avg Fwd Segment Size',\n",
        "                     'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n",
        "                     'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
        "                     'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes',\n",
        "                     'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
        "                     'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Remove non-numeric columns\n",
        "df = df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Print the first 5 rows of the dataframe\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Splitting the dataset into features (X) and target (y)\n",
        "X = df.drop(columns=['Class'])  # Features\n",
        "y = df['Class']  # Target variable\n",
        "\n",
        "# Splitting the dataset into training (70%), testing (15%), and validation (15%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Printing the shapes of the resulting datasets\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wSDE1B46pm1",
        "outputId": "2765550f-1b7d-4e94-f940-42216d1bf708"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  Protocol  Flow Duration  Total Fwd Packets  \\\n",
            "0           0         2   1.805269e-03           0.000058   \n",
            "1           1         2   8.333421e-09           0.000012   \n",
            "2           2         2   3.916708e-07           0.000012   \n",
            "3           3         2   8.943260e-04           0.000035   \n",
            "4           4         2   8.939260e-04           0.000035   \n",
            "\n",
            "   Total Backward Packets  Fwd Packets Length Total  Bwd Packets Length Total  \\\n",
            "0                     0.0                  0.000137                       0.0   \n",
            "1                     0.0                  0.000053                       0.0   \n",
            "2                     0.0                  0.000050                       0.0   \n",
            "3                     0.0                  0.000092                       0.0   \n",
            "4                     0.0                  0.000094                       0.0   \n",
            "\n",
            "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  ...  \\\n",
            "0               0.012235               0.150634                0.115412  ...   \n",
            "1               0.012484               0.188175                0.132989  ...   \n",
            "2               0.011924               0.179728                0.127019  ...   \n",
            "3               0.011488               0.154857                0.115909  ...   \n",
            "4               0.012111               0.154857                0.119226  ...   \n",
            "\n",
            "   Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \\\n",
            "0          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "1          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "2          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "3          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "4          0.0         0.0         0.0         0.0        0.0       0.0   \n",
            "\n",
            "   Idle Max  Idle Min  Label  Class  \n",
            "0       0.0       0.0     14      1  \n",
            "1       0.0       0.0     14      1  \n",
            "2       0.0       0.0     14      1  \n",
            "3       0.0       0.0     14      1  \n",
            "4       0.0       0.0     14      1  \n",
            "\n",
            "[5 rows x 80 columns]\n",
            "Training set shape: (301959, 79) (301959,)\n",
            "Testing set shape: (64706, 79) (64706,)\n",
            "Validation set shape: (64706, 79) (64706,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning model by using even larger batch size and changing other few parameters to achieve accuracy with low learning time."
      ],
      "metadata": {
        "id": "E7UPV3dH7Thh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time\n",
        "\n",
        "# Check GPU availability and set memory growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU is available and memory growth is set.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU available, falling back to CPU.\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with larger batch size and longer training time\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=2048)\n",
        "\n",
        "# Calculate the time taken for training\n",
        "training_time = time.time() - start_time\n",
        "print(\"Training time:\", training_time, \"seconds\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWA4C-Qz6tyj",
        "outputId": "ce29fa2f-1628-4346-f443-7106836ab5d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available and memory growth is set.\n",
            "Epoch 1/50\n",
            "148/148 [==============================] - 6s 11ms/step - loss: 515221.4375 - accuracy: 0.6891 - val_loss: 149638.6406 - val_accuracy: 0.7726\n",
            "Epoch 2/50\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 222152.6406 - accuracy: 0.6837 - val_loss: 88814.6016 - val_accuracy: 0.7730\n",
            "Epoch 3/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 168094.0938 - accuracy: 0.6732 - val_loss: 59524.8984 - val_accuracy: 0.7730\n",
            "Epoch 4/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 139814.5625 - accuracy: 0.6694 - val_loss: 48538.2617 - val_accuracy: 0.7731\n",
            "Epoch 5/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 127157.8750 - accuracy: 0.6686 - val_loss: 36977.7617 - val_accuracy: 0.7730\n",
            "Epoch 6/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 101314.6172 - accuracy: 0.6702 - val_loss: 32520.5020 - val_accuracy: 0.7726\n",
            "Epoch 7/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 97896.7812 - accuracy: 0.6723 - val_loss: 23107.6641 - val_accuracy: 0.2502\n",
            "Epoch 8/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 79855.7422 - accuracy: 0.6743 - val_loss: 18202.0078 - val_accuracy: 0.7714\n",
            "Epoch 9/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 69027.7422 - accuracy: 0.6756 - val_loss: 16305.5146 - val_accuracy: 0.5200\n",
            "Epoch 10/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 58538.8438 - accuracy: 0.6778 - val_loss: 14695.4434 - val_accuracy: 0.2952\n",
            "Epoch 11/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 54021.8398 - accuracy: 0.6809 - val_loss: 15539.5889 - val_accuracy: 0.2866\n",
            "Epoch 12/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 53917.3477 - accuracy: 0.6820 - val_loss: 10443.4229 - val_accuracy: 0.7497\n",
            "Epoch 13/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 43562.4414 - accuracy: 0.6857 - val_loss: 10905.1826 - val_accuracy: 0.6108\n",
            "Epoch 14/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 41568.8047 - accuracy: 0.6750 - val_loss: 8429.2305 - val_accuracy: 0.6716\n",
            "Epoch 15/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 36579.5664 - accuracy: 0.6986 - val_loss: 7906.2529 - val_accuracy: 0.7379\n",
            "Epoch 16/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 35865.6094 - accuracy: 0.7197 - val_loss: 5722.6743 - val_accuracy: 0.8325\n",
            "Epoch 17/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 29272.0332 - accuracy: 0.7444 - val_loss: 5707.7329 - val_accuracy: 0.8720\n",
            "Epoch 18/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 29519.4238 - accuracy: 0.7518 - val_loss: 4664.7866 - val_accuracy: 0.8197\n",
            "Epoch 19/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 26958.5918 - accuracy: 0.7685 - val_loss: 5187.1504 - val_accuracy: 0.9068\n",
            "Epoch 20/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 24286.4316 - accuracy: 0.7962 - val_loss: 4145.3940 - val_accuracy: 0.8944\n",
            "Epoch 21/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 22837.8535 - accuracy: 0.8000 - val_loss: 3201.8853 - val_accuracy: 0.8896\n",
            "Epoch 22/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 20992.5020 - accuracy: 0.8008 - val_loss: 2159.9043 - val_accuracy: 0.8831\n",
            "Epoch 23/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 19411.1758 - accuracy: 0.8084 - val_loss: 2217.6123 - val_accuracy: 0.8939\n",
            "Epoch 24/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 17788.6719 - accuracy: 0.8078 - val_loss: 1873.2606 - val_accuracy: 0.8661\n",
            "Epoch 25/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 15426.1670 - accuracy: 0.8004 - val_loss: 1888.2990 - val_accuracy: 0.8886\n",
            "Epoch 26/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 14592.7500 - accuracy: 0.7971 - val_loss: 1535.8208 - val_accuracy: 0.8910\n",
            "Epoch 27/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 14677.7930 - accuracy: 0.7977 - val_loss: 1047.7699 - val_accuracy: 0.8831\n",
            "Epoch 28/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 12940.1074 - accuracy: 0.7932 - val_loss: 802.5898 - val_accuracy: 0.8783\n",
            "Epoch 29/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 10534.9121 - accuracy: 0.7943 - val_loss: 1086.7002 - val_accuracy: 0.8756\n",
            "Epoch 30/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 11690.2812 - accuracy: 0.7942 - val_loss: 1151.2015 - val_accuracy: 0.8683\n",
            "Epoch 31/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 10420.8887 - accuracy: 0.7943 - val_loss: 680.1254 - val_accuracy: 0.8142\n",
            "Epoch 32/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 9822.3428 - accuracy: 0.7926 - val_loss: 475.3146 - val_accuracy: 0.8647\n",
            "Epoch 33/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 7798.8237 - accuracy: 0.7948 - val_loss: 278.5858 - val_accuracy: 0.8695\n",
            "Epoch 34/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 6825.1045 - accuracy: 0.7943 - val_loss: 105.4128 - val_accuracy: 0.8697\n",
            "Epoch 35/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 6486.9453 - accuracy: 0.7946 - val_loss: 98.8929 - val_accuracy: 0.8881\n",
            "Epoch 36/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 4842.2124 - accuracy: 0.7959 - val_loss: 93.1640 - val_accuracy: 0.8664\n",
            "Epoch 37/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 5139.2769 - accuracy: 0.7980 - val_loss: 85.2466 - val_accuracy: 0.8313\n",
            "Epoch 38/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 5068.7773 - accuracy: 0.7979 - val_loss: 81.5570 - val_accuracy: 0.7992\n",
            "Epoch 39/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 3946.1179 - accuracy: 0.8003 - val_loss: 78.6573 - val_accuracy: 0.8526\n",
            "Epoch 40/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 3761.2986 - accuracy: 0.7985 - val_loss: 74.3772 - val_accuracy: 0.8859\n",
            "Epoch 41/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 3813.3542 - accuracy: 0.7967 - val_loss: 69.4205 - val_accuracy: 0.8938\n",
            "Epoch 42/50\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 2524.8450 - accuracy: 0.7965 - val_loss: 63.2378 - val_accuracy: 0.8724\n",
            "Epoch 43/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 3595.5767 - accuracy: 0.7955 - val_loss: 66.1715 - val_accuracy: 0.8299\n",
            "Epoch 44/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2941.5559 - accuracy: 0.7960 - val_loss: 68.2600 - val_accuracy: 0.8862\n",
            "Epoch 45/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 1544.5969 - accuracy: 0.7944 - val_loss: 65.6194 - val_accuracy: 0.7735\n",
            "Epoch 46/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 1925.5157 - accuracy: 0.7937 - val_loss: 76.7897 - val_accuracy: 0.7732\n",
            "Epoch 47/50\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 1487.5049 - accuracy: 0.7914 - val_loss: 75.4151 - val_accuracy: 0.7732\n",
            "Epoch 48/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 1352.7428 - accuracy: 0.7903 - val_loss: 77.3526 - val_accuracy: 0.7732\n",
            "Epoch 49/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 1202.7665 - accuracy: 0.7920 - val_loss: 85.2183 - val_accuracy: 0.7732\n",
            "Epoch 50/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 1578.0138 - accuracy: 0.7974 - val_loss: 87.5944 - val_accuracy: 0.7734\n",
            "Training time: 50.2617449760437 seconds\n",
            "2023/2023 [==============================] - 5s 2ms/step - loss: 854.0618 - accuracy: 0.7754\n",
            "Test Accuracy: 0.7754303812980652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incorporating distributed strategy as a way to demo federated learning."
      ],
      "metadata": {
        "id": "8HkhzPb_7ow7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time\n",
        "\n",
        "# Check GPU availability and set memory growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU is available and memory growth is set.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU available, falling back to CPU.\")\n",
        "\n",
        "# Define the distributed strategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define the model inside the strategy scope\n",
        "with strategy.scope():\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile the model with a lower learning rate\n",
        "    opt = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model with larger batch size and longer training time\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=2048)\n",
        "\n",
        "# Calculate the time taken for training\n",
        "training_time = time.time() - start_time\n",
        "print(\"Training time:\", training_time, \"seconds\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAS-Z6cB62_v",
        "outputId": "5496a9a1-f36d-4a8f-be2d-230e198c0e5f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available and memory growth is set.\n",
            "Epoch 1/50\n",
            "148/148 [==============================] - 3s 11ms/step - loss: 565311.3750 - accuracy: 0.6550 - val_loss: 150939.7812 - val_accuracy: 0.7726\n",
            "Epoch 2/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 248582.8750 - accuracy: 0.6725 - val_loss: 83667.5938 - val_accuracy: 0.7730\n",
            "Epoch 3/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 166762.7344 - accuracy: 0.6529 - val_loss: 61831.7500 - val_accuracy: 0.7730\n",
            "Epoch 4/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 138403.5938 - accuracy: 0.6555 - val_loss: 50695.3633 - val_accuracy: 0.7731\n",
            "Epoch 5/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 113733.1562 - accuracy: 0.6602 - val_loss: 38788.5234 - val_accuracy: 0.7731\n",
            "Epoch 6/50\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 102309.1875 - accuracy: 0.6601 - val_loss: 30556.4082 - val_accuracy: 0.7731\n",
            "Epoch 7/50\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 73628.9062 - accuracy: 0.6657 - val_loss: 27936.2441 - val_accuracy: 0.7731\n",
            "Epoch 8/50\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 81686.9453 - accuracy: 0.6703 - val_loss: 21592.5703 - val_accuracy: 0.7730\n",
            "Epoch 9/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 67086.9141 - accuracy: 0.6648 - val_loss: 18090.9590 - val_accuracy: 0.7728\n",
            "Epoch 10/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 51833.2070 - accuracy: 0.6675 - val_loss: 16868.7656 - val_accuracy: 0.7724\n",
            "Epoch 11/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 54889.2617 - accuracy: 0.6711 - val_loss: 13393.0488 - val_accuracy: 0.7679\n",
            "Epoch 12/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 51021.7148 - accuracy: 0.6730 - val_loss: 10257.5898 - val_accuracy: 0.7649\n",
            "Epoch 13/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 41962.2227 - accuracy: 0.6720 - val_loss: 7668.2705 - val_accuracy: 0.7555\n",
            "Epoch 14/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 38792.0117 - accuracy: 0.7026 - val_loss: 7414.8105 - val_accuracy: 0.7530\n",
            "Epoch 15/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 36516.0586 - accuracy: 0.7309 - val_loss: 7151.9624 - val_accuracy: 0.8154\n",
            "Epoch 16/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 33126.6797 - accuracy: 0.7514 - val_loss: 5332.9888 - val_accuracy: 0.8447\n",
            "Epoch 17/50\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 27226.3516 - accuracy: 0.7462 - val_loss: 5134.4258 - val_accuracy: 0.9030\n",
            "Epoch 18/50\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 26497.6543 - accuracy: 0.7473 - val_loss: 5268.8789 - val_accuracy: 0.9003\n",
            "Epoch 19/50\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 26868.9473 - accuracy: 0.7633 - val_loss: 4214.7876 - val_accuracy: 0.8139\n",
            "Epoch 20/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 24690.0449 - accuracy: 0.7577 - val_loss: 3206.2729 - val_accuracy: 0.7731\n",
            "Epoch 21/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 22292.0371 - accuracy: 0.7569 - val_loss: 2540.8806 - val_accuracy: 0.7731\n",
            "Epoch 22/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 19946.8340 - accuracy: 0.7594 - val_loss: 2578.5872 - val_accuracy: 0.7731\n",
            "Epoch 23/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 17120.3789 - accuracy: 0.7623 - val_loss: 2182.7390 - val_accuracy: 0.7731\n",
            "Epoch 24/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 18237.9961 - accuracy: 0.7622 - val_loss: 1726.7917 - val_accuracy: 0.7731\n",
            "Epoch 25/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 14683.2256 - accuracy: 0.7644 - val_loss: 1506.0262 - val_accuracy: 0.7731\n",
            "Epoch 26/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 14903.6172 - accuracy: 0.7647 - val_loss: 1040.8391 - val_accuracy: 0.7731\n",
            "Epoch 27/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 14544.9414 - accuracy: 0.7665 - val_loss: 504.1651 - val_accuracy: 0.7731\n",
            "Epoch 28/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 12901.6250 - accuracy: 0.7671 - val_loss: 665.0547 - val_accuracy: 0.7731\n",
            "Epoch 29/50\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 10965.0566 - accuracy: 0.7673 - val_loss: 364.2399 - val_accuracy: 0.7731\n",
            "Epoch 30/50\n",
            "148/148 [==============================] - 2s 13ms/step - loss: 11105.6006 - accuracy: 0.7682 - val_loss: 613.1153 - val_accuracy: 0.7731\n",
            "Epoch 31/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 8949.4297 - accuracy: 0.7680 - val_loss: 702.9295 - val_accuracy: 0.7731\n",
            "Epoch 32/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 9943.2705 - accuracy: 0.7680 - val_loss: 420.5315 - val_accuracy: 0.7731\n",
            "Epoch 33/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 8380.2646 - accuracy: 0.7687 - val_loss: 225.3948 - val_accuracy: 0.7732\n",
            "Epoch 34/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 7907.3936 - accuracy: 0.7686 - val_loss: 637.4410 - val_accuracy: 0.7731\n",
            "Epoch 35/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 5576.3989 - accuracy: 0.7689 - val_loss: 500.2881 - val_accuracy: 0.7731\n",
            "Epoch 36/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 6754.5029 - accuracy: 0.7693 - val_loss: 252.1209 - val_accuracy: 0.7732\n",
            "Epoch 37/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 6282.9785 - accuracy: 0.7690 - val_loss: 68.5940 - val_accuracy: 0.7731\n",
            "Epoch 38/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 5248.8071 - accuracy: 0.7692 - val_loss: 65.5792 - val_accuracy: 0.7731\n",
            "Epoch 39/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 5098.6924 - accuracy: 0.7696 - val_loss: 61.4281 - val_accuracy: 0.7732\n",
            "Epoch 40/50\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 4377.2900 - accuracy: 0.7698 - val_loss: 55.9546 - val_accuracy: 0.7731\n",
            "Epoch 41/50\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 4067.4321 - accuracy: 0.7699 - val_loss: 51.5440 - val_accuracy: 0.7731\n",
            "Epoch 42/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 2958.2026 - accuracy: 0.7704 - val_loss: 49.1947 - val_accuracy: 0.7731\n",
            "Epoch 43/50\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 3636.4790 - accuracy: 0.7703 - val_loss: 49.9079 - val_accuracy: 0.7731\n",
            "Epoch 44/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 2968.9778 - accuracy: 0.7701 - val_loss: 46.1486 - val_accuracy: 0.7731\n",
            "Epoch 45/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 1988.9388 - accuracy: 0.7706 - val_loss: 47.2068 - val_accuracy: 0.7731\n",
            "Epoch 46/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 1939.3357 - accuracy: 0.7704 - val_loss: 42.3100 - val_accuracy: 0.7731\n",
            "Epoch 47/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 1825.3530 - accuracy: 0.7708 - val_loss: 38.2430 - val_accuracy: 0.7731\n",
            "Epoch 48/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 1557.9916 - accuracy: 0.7709 - val_loss: 33.0701 - val_accuracy: 0.7731\n",
            "Epoch 49/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 2222.1787 - accuracy: 0.7707 - val_loss: 33.9054 - val_accuracy: 0.7731\n",
            "Epoch 50/50\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 1477.1396 - accuracy: 0.7704 - val_loss: 34.6026 - val_accuracy: 0.7731\n",
            "Training time: 83.66790819168091 seconds\n",
            "2023/2023 [==============================] - 8s 4ms/step - loss: 307.2076 - accuracy: 0.7750\n",
            "Test Accuracy: 0.7750440239906311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "# Assuming the data is already preprocessed and split into X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "# Define the distributed strategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define the model inside the strategy scope\n",
        "with strategy.scope():\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile the model with a lower learning rate\n",
        "    opt = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model with larger batch size and longer training time\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=2048)\n",
        "\n",
        "# Calculate the time taken for training\n",
        "training_time = time.time() - start_time\n",
        "print(\"Training time:\", training_time, \"seconds\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtjrpm_jB6JX",
        "outputId": "f29def2b-b029-490e-f198-4ac2dcd5086b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 3s 10ms/step - loss: 747129.2500 - accuracy: 0.6050 - val_loss: 182662.8438 - val_accuracy: 0.7726\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 260450.2812 - accuracy: 0.6567 - val_loss: 106290.6875 - val_accuracy: 0.7730\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 163451.5000 - accuracy: 0.6468 - val_loss: 75903.5703 - val_accuracy: 0.7730\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 144583.8438 - accuracy: 0.6483 - val_loss: 59863.9375 - val_accuracy: 0.7731\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 112170.9688 - accuracy: 0.6499 - val_loss: 46508.1328 - val_accuracy: 0.7731\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 106620.7578 - accuracy: 0.6511 - val_loss: 34198.5273 - val_accuracy: 0.7731\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 91880.5156 - accuracy: 0.6541 - val_loss: 29396.4473 - val_accuracy: 0.7731\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 1s 10ms/step - loss: 76826.5234 - accuracy: 0.6535 - val_loss: 24236.0176 - val_accuracy: 0.7731\n",
            "Epoch 9/20\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 72636.7422 - accuracy: 0.6608 - val_loss: 18682.7148 - val_accuracy: 0.7731\n",
            "Epoch 10/20\n",
            "148/148 [==============================] - 2s 11ms/step - loss: 59546.5898 - accuracy: 0.6580 - val_loss: 15184.7705 - val_accuracy: 0.7729\n",
            "Epoch 11/20\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 56191.4258 - accuracy: 0.6641 - val_loss: 12944.8682 - val_accuracy: 0.7724\n",
            "Epoch 12/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 52091.0195 - accuracy: 0.6657 - val_loss: 11395.8037 - val_accuracy: 0.7702\n",
            "Epoch 13/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 50479.5039 - accuracy: 0.6676 - val_loss: 9644.9150 - val_accuracy: 0.7718\n",
            "Epoch 14/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 42746.1055 - accuracy: 0.7392 - val_loss: 8265.5244 - val_accuracy: 0.8485\n",
            "Epoch 15/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 40715.8672 - accuracy: 0.7421 - val_loss: 7167.0181 - val_accuracy: 0.8418\n",
            "Epoch 16/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 30121.3594 - accuracy: 0.7348 - val_loss: 6636.4644 - val_accuracy: 0.7731\n",
            "Epoch 17/20\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 36096.1992 - accuracy: 0.7431 - val_loss: 5529.1313 - val_accuracy: 0.7731\n",
            "Epoch 18/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 35175.0664 - accuracy: 0.7479 - val_loss: 4792.3037 - val_accuracy: 0.7731\n",
            "Epoch 19/20\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 29045.6133 - accuracy: 0.7520 - val_loss: 3731.0098 - val_accuracy: 0.7731\n",
            "Epoch 20/20\n",
            "148/148 [==============================] - 2s 12ms/step - loss: 25813.8809 - accuracy: 0.7556 - val_loss: 3312.5261 - val_accuracy: 0.7731\n",
            "Training time: 43.26845836639404 seconds\n",
            "2023/2023 [==============================] - 7s 3ms/step - loss: 5970.7524 - accuracy: 0.7750\n",
            "Test Accuracy: 0.7750440239906311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "# Assuming the data is already preprocessed and split into X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=2048)\n",
        "\n",
        "# Calculate the time taken for training\n",
        "training_time = time.time() - start_time\n",
        "print(\"Training time:\", training_time, \"seconds\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlZsCGmyCELt",
        "outputId": "73b6de03-866f-4f31-eb22-113687f60df1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "148/148 [==============================] - 3s 8ms/step - loss: 380838.2188 - accuracy: 0.6934 - val_loss: 80641.6094 - val_accuracy: 0.7730\n",
            "Epoch 2/20\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 198630.6406 - accuracy: 0.6797 - val_loss: 49684.8867 - val_accuracy: 0.7730\n",
            "Epoch 3/20\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 150976.6406 - accuracy: 0.6759 - val_loss: 37363.8320 - val_accuracy: 0.7730\n",
            "Epoch 4/20\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 128453.2031 - accuracy: 0.6763 - val_loss: 29597.9863 - val_accuracy: 0.7731\n",
            "Epoch 5/20\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 96213.4766 - accuracy: 0.6696 - val_loss: 23626.4453 - val_accuracy: 0.7731\n",
            "Epoch 6/20\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 78474.6875 - accuracy: 0.6693 - val_loss: 18444.6270 - val_accuracy: 0.7730\n",
            "Epoch 7/20\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 78159.6797 - accuracy: 0.6763 - val_loss: 14542.9580 - val_accuracy: 0.7727\n",
            "Epoch 8/20\n",
            "148/148 [==============================] - 1s 7ms/step - loss: 66404.6094 - accuracy: 0.6737 - val_loss: 15068.4365 - val_accuracy: 0.7728\n",
            "Epoch 9/20\n",
            "148/148 [==============================] - 1s 8ms/step - loss: 63073.9844 - accuracy: 0.6787 - val_loss: 13657.5449 - val_accuracy: 0.7723\n",
            "Epoch 10/20\n",
            "148/148 [==============================] - 1s 9ms/step - loss: 51807.1992 - accuracy: 0.6797 - val_loss: 12639.9131 - val_accuracy: 0.7721\n",
            "Epoch 11/20\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 48230.2031 - accuracy: 0.6820 - val_loss: 11408.6426 - val_accuracy: 0.7707\n",
            "Epoch 12/20\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 40582.1055 - accuracy: 0.6844 - val_loss: 9522.1826 - val_accuracy: 0.7683\n",
            "Epoch 13/20\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 35430.4375 - accuracy: 0.6861 - val_loss: 6630.5552 - val_accuracy: 0.7242\n",
            "Epoch 14/20\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 37583.1523 - accuracy: 0.6861 - val_loss: 5919.9229 - val_accuracy: 0.5122\n",
            "Epoch 15/20\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 32451.4531 - accuracy: 0.6822 - val_loss: 4623.5381 - val_accuracy: 0.7108\n",
            "Epoch 16/20\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 28288.2051 - accuracy: 0.7003 - val_loss: 3695.0791 - val_accuracy: 0.6558\n",
            "Epoch 17/20\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 27053.1797 - accuracy: 0.7251 - val_loss: 2609.3933 - val_accuracy: 0.7939\n",
            "Epoch 18/20\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 26381.7832 - accuracy: 0.7362 - val_loss: 2450.7209 - val_accuracy: 0.8134\n",
            "Epoch 19/20\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 21585.6309 - accuracy: 0.7616 - val_loss: 2259.5088 - val_accuracy: 0.9010\n",
            "Epoch 20/20\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 22062.8379 - accuracy: 0.7671 - val_loss: 2068.4202 - val_accuracy: 0.8793\n",
            "Training time: 19.95212984085083 seconds\n",
            "2023/2023 [==============================] - 6s 3ms/step - loss: 3668.1189 - accuracy: 0.8781\n",
            "Test Accuracy: 0.8780792951583862\n"
          ]
        }
      ]
    }
  ]
}